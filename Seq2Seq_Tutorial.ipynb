{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-25 11:08:53--  https://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15374406 (15M) [application/zip]\n",
      "Saving to: ‘rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  14.66M  5.48MB/s    in 2.7s    \n",
      "\n",
      "2023-03-25 11:08:57 (5.48 MB/s) - ‘rus-eng.zip’ saved [15374406/15374406]\n",
      "\n",
      "Archive:  rus-eng.zip\n",
      "  inflating: rus.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/rus-eng.zip\n",
    "!unzip rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"./src\"))\n",
    "\n",
    "from models.rnn import Seq2SeqRNN\n",
    "from data.datamodule import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "def filter_func(x):\n",
    "    len_filter = lambda x: max(len(x[0].split(\" \")), len(x[1].split(\" \"))) <= 5\n",
    "    prefix_filter = lambda x: x[0].startswith(eng_prefixes)\n",
    "    return len_filter(x) and prefix_filter(x)\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 256,          # <--- size of batch\n",
    "    \"num_workers\": 16,          # <--- num cpu to use in dataloader\n",
    "    \"filter\": filter_func,      # <--- callable obj to filter data  \n",
    "    \"filename\": \"./rus.txt\",    # <--- path to file with sentneces\n",
    "    \"lang1\": \"en\",              # <--- name of the first lang    \n",
    "    \"lang2\": \"ru\",              # <--- name of the second lang\n",
    "    \"reverse\": False,           # <--- direct or reverse order in pairs\n",
    "    \"train_size\": 0.8,          # <--- ratio of data pairs to use in train\n",
    "    \"run_name\": \"tutorial\",     # <--- run name to logger and checkpoints\n",
    "    \"quantile\": 0.95,           # <--- (1 - quantile) longest sentences will be removed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from file: 100%|██████████| 464010/464010 [00:05<00:00, 80902.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data manager\n",
    "dm = DataManager(config)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "input_lang_n_words = dm.input_lang_n_words\n",
    "output_lang_n_words = dm.output_lang_n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqRNN(\n",
    "    encoder_vocab_size=input_lang_n_words,\n",
    "    encoder_embedding_size=256,\n",
    "    decoder_embedding_size=256,\n",
    "    decoder_output_size=output_lang_n_words,\n",
    "    lr=1e-3,\n",
    "    output_lang_index2word=dm.train_dataset.output_lang.index2word,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toomuch/anaconda3/envs/translation/lib/python3.10/site-packages/lightning_fabric/connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# TB Logger\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=config[\"run_name\"])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"runs/{}/\".format(config[\"run_name\"]),\n",
    "    filename=\"{epoch:02d}-{step:d}-{val_loss:.4f}\",\n",
    "    verbose=True,\n",
    "    every_n_epochs=1,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "# Initialize a Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cuda\",\n",
    "    devices=[2],\n",
    "    precision=16,\n",
    "    max_epochs=50,\n",
    "    min_epochs=1,\n",
    "    callbacks=[lr_monitor, checkpoint_callback],\n",
    "    check_val_every_n_epoch=1,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from file: 100%|██████████| 464010/464010 [00:05<00:00, 82091.54it/s]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/tutorial\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | EncoderRNN | 1.1 M \n",
      "1 | decoder   | DecoderRNN | 3.3 M \n",
      "2 | criterion | NLLLoss    | 0     \n",
      "-----------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.465    Total estimated model params size (MB)\n",
      "2023-03-25 11:09:28.243083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]проблема не в ---> чрезвычайно ответственность расстроены пиво\n",
      "я жду обеда ---> завидую находчивый твердая олимпиаду\n",
      "мы так счастливы ---> тактична делать худой шляпе\n",
      "я на вашей ---> голодны спокойная пьёт помолвлена\n",
      "я предвзят ---> завидую находчивый твердая олимпиаду\n",
      "вы владельцы ---> строен запад запад гольф\n",
      "мы не в ---> чрезвычайно ответственность расстроены пиво\n",
      "завтра мы не ---> мальчики шарф завидуете культурист\n",
      "ей семнадцать лет ---> чрезвычайно ответственность расстроены пиво\n",
      "ты совершенно здорова ---> тупорылый стреляю океанограф ведёте\n",
      "мы все счастливы ---> чрезвычайно ответственность расстроены пиво\n",
      "он ленивый ---> завидую находчивый твердая олимпиаду\n",
      "мы не такие ---> тупорылый ожидаем говорите говорите\n",
      "я устал от ---> строен запад запад гольф\n",
      "он оскорблён ---> влюблена сердиты усердный выживем\n",
      "Epoch 0: 100%|██████████| 41/41 [00:05<00:00,  7.33it/s, v_num=0, train_bleu=0.000, train_loss=3.120]проблема не в ---> я не\n",
      "я жду обеда ---> я не\n",
      "мы так счастливы ---> я не\n",
      "я на вашей ---> я не\n",
      "я предвзят ---> я не\n",
      "вы владельцы ---> я не\n",
      "мы не в ---> я не\n",
      "завтра мы не ---> я не\n",
      "ей семнадцать лет ---> я не\n",
      "ты совершенно здорова ---> я не\n",
      "мы все счастливы ---> я не\n",
      "он ленивый ---> я не\n",
      "мы не такие ---> я не\n",
      "я устал от ---> я не\n",
      "он оскорблён ---> я не\n",
      "Epoch 0: 100%|██████████| 41/41 [00:10<00:00,  4.06it/s, v_num=0, train_bleu=0.000, train_loss=3.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 41: 'val_loss' reached 3.12502 (best 3.12502), saving model to '/home/toomuch/somov/machine-translation/fork/pytorch-machine-translation/runs/tutorial/epoch=00-step=41-val_loss=3.1250.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 18/41 [00:04<00:06,  3.77it/s, v_num=0, train_bleu=0.000, train_loss=2.960]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toomuch/anaconda3/envs/translation/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see tensorboard logs in two ways: launch tensorboard extension in jupyter notebook or use CLI method.\n",
    "\n",
    "CLI:\n",
    "1. Tap `tensorboard --logdir=./lightning_logs --port=6006`\n",
    "2. Forward selected port in the ssh connection if you are working remote else just open `localhost:6006` in the browser\n",
    "\n",
    "\n",
    "Jupyter:\n",
    "1. Load extension: `%load_ext tensorboard`\n",
    "2. Launch built-in tensorboard: `%tensorboard --logdir=./lightning_logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints\n",
    "\n",
    "#### Load model from checkpoint\n",
    "Using `self.save_hyperparameters` in `__init__` body of `pl.LightningModule` allows to load model in this way:\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "model = Seq2SeqRNN.load_from_checkpoint('checkpoint.ckpt')\n",
    "```\n",
    "\n",
    "Or you can load checkpoint in natural pytorch way:\n",
    "```python\n",
    "model = Seq2SeqRNN(*args, **kwargs)\n",
    "model.load_state_dict(torch.load('checkpoint.ckpt')['state_dict'])\n",
    "```\n",
    "\n",
    "#### Add custom metrics to logger\n",
    "https://lightning.ai/docs/pytorch/stable/extensions/logging.html\n",
    "\n",
    "\n",
    "#### Enable grad accumulation\n",
    "In this example accumulation will be the following: \n",
    "1. from 0 to 15th epoch accumulate 4 batches\n",
    "2. from 15th to 25th epoch accumulate 2 batches\n",
    "3. from 25th epoch accumulate 1 batch\n",
    "\n",
    "```python\n",
    "from pytorch_lightning.callbacks import GradientAccumulationScheduler\n",
    "\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: 4, 15: 2, 25: 1})\n",
    "trainer = pl.Trainer(\n",
    "    ...\n",
    "    callbacks=[..., accumulator],\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "#### Configure learning rate scheduler\n",
    "\n",
    "```python\n",
    "def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=0,\n",
    "        threshold=1e-2,\n",
    "        threshold_mode='rel',\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "        eps=1e-09,\n",
    "        verbose=True\n",
    "    )\n",
    "    lr_dict = {\n",
    "        \"scheduler\": lr_scheduler,\n",
    "        \"interval\": \"epoch\",\n",
    "        \"frequency\": 1,\n",
    "        \"monitor\": \"val_loss\"\n",
    "    }\n",
    "    return [optimizer], [lr_dict]\n",
    "```\n",
    "\n",
    "#### Other logger: WandB\n",
    "You can use famous weights&biases logger which is natively supports in pytorch-lightning:\n",
    "https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.wandb.html#module-lightning.pytorch.loggers.wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
